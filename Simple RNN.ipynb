{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_rooms</th>\n",
       "      <th>floor_on</th>\n",
       "      <th>total_floors</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>pincode</th>\n",
       "      <th>balkon</th>\n",
       "      <th>terrasse</th>\n",
       "      <th>garten</th>\n",
       "      <th>Gaste-WC</th>\n",
       "      <th>Aufzug</th>\n",
       "      <th>wohung</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>living_area_m2</th>\n",
       "      <th>transform_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>8.535089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>8.517393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021</td>\n",
       "      <td>5.259732</td>\n",
       "      <td>8.653742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1968</td>\n",
       "      <td>4.335197</td>\n",
       "      <td>8.638011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4.262680</td>\n",
       "      <td>8.443301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_rooms  floor_on  total_floors  bedroom  pincode  balkon  \\\n",
       "0              2.0         0             0        0    12209       1   \n",
       "1              3.0         0             0        0    12209       1   \n",
       "2              5.0         0             3        3    12209       1   \n",
       "3              2.5         1             2        1    12209       1   \n",
       "4              2.5         2             2        2    12209       1   \n",
       "\n",
       "   terrasse  garten  Gaste-WC  Aufzug  wohung  construction_year  \\\n",
       "0         1       0         0       0       1               1997   \n",
       "1         1       0         0       0       1               1997   \n",
       "2         1       1         1       1       0               2021   \n",
       "3         1       0         0       0       1               1968   \n",
       "4         1       1         0       0       1               2018   \n",
       "\n",
       "   living_area_m2  transform_price  \n",
       "0        4.043051         8.535089  \n",
       "1        4.442651         8.517393  \n",
       "2        5.259732         8.653742  \n",
       "3        4.335197         8.638011  \n",
       "4        4.262680         8.443301  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'F:\\amruth\\after_preprocess_data.csv', encoding = 'iso-8859-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data[['transform_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transform_price'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12743, 13), (12743, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12424, 13), (12424, 1), (319, 13))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.025, random_state = 0)\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis = -1), input_shape = [None]),\n",
    "    tf.keras.layers.SimpleRNN(100, return_sequences = True),\n",
    "    tf.keras.layers.SimpleRNN(80, return_sequences = True),\n",
    "    tf.keras.layers.SimpleRNN(40),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12424 samples, validate on 319 samples\n",
      "Epoch 1/50\n",
      "12424/12424 [==============================] - 5s 367us/sample - loss: 1.0659 - mae: 0.4718 - val_loss: 0.1492 - val_mae: 0.2754\n",
      "Epoch 2/50\n",
      "12424/12424 [==============================] - 3s 270us/sample - loss: 0.1220 - mae: 0.2567 - val_loss: 0.1261 - val_mae: 0.2503\n",
      "Epoch 3/50\n",
      "12424/12424 [==============================] - 5s 374us/sample - loss: 0.1146 - mae: 0.2499 - val_loss: 0.1185 - val_mae: 0.2445\n",
      "Epoch 4/50\n",
      "12424/12424 [==============================] - 4s 310us/sample - loss: 0.1122 - mae: 0.2476 - val_loss: 0.1181 - val_mae: 0.2451\n",
      "Epoch 5/50\n",
      "12424/12424 [==============================] - 3s 255us/sample - loss: 0.1121 - mae: 0.2471 - val_loss: 0.1136 - val_mae: 0.2416\n",
      "Epoch 6/50\n",
      "12424/12424 [==============================] - 4s 313us/sample - loss: 0.1104 - mae: 0.2459 - val_loss: 0.1225 - val_mae: 0.2518\n",
      "Epoch 7/50\n",
      "12424/12424 [==============================] - 3s 258us/sample - loss: 0.1093 - mae: 0.2438 - val_loss: 0.1118 - val_mae: 0.2415\n",
      "Epoch 8/50\n",
      "12424/12424 [==============================] - 3s 252us/sample - loss: 0.1087 - mae: 0.2435 - val_loss: 0.1286 - val_mae: 0.2572\n",
      "Epoch 9/50\n",
      "12424/12424 [==============================] - 3s 242us/sample - loss: 0.1071 - mae: 0.2416 - val_loss: 0.1105 - val_mae: 0.2408\n",
      "Epoch 10/50\n",
      "12424/12424 [==============================] - 3s 243us/sample - loss: 0.1073 - mae: 0.2416 - val_loss: 0.1042 - val_mae: 0.2353\n",
      "Epoch 11/50\n",
      "12424/12424 [==============================] - 3s 243us/sample - loss: 0.1053 - mae: 0.2389 - val_loss: 0.1043 - val_mae: 0.2355\n",
      "Epoch 12/50\n",
      "12424/12424 [==============================] - 3s 251us/sample - loss: 0.1052 - mae: 0.2386 - val_loss: 0.0976 - val_mae: 0.2326\n",
      "Epoch 13/50\n",
      "12424/12424 [==============================] - 3s 267us/sample - loss: 0.1053 - mae: 0.2386 - val_loss: 0.1013 - val_mae: 0.2319\n",
      "Epoch 14/50\n",
      "12424/12424 [==============================] - 3s 266us/sample - loss: 0.1033 - mae: 0.2361 - val_loss: 0.0936 - val_mae: 0.2271\n",
      "Epoch 15/50\n",
      "12424/12424 [==============================] - 3s 271us/sample - loss: 0.1030 - mae: 0.2350 - val_loss: 0.0950 - val_mae: 0.2321\n",
      "Epoch 16/50\n",
      "12424/12424 [==============================] - 3s 277us/sample - loss: 0.1033 - mae: 0.2353 - val_loss: 0.1061 - val_mae: 0.2378\n",
      "Epoch 17/50\n",
      "12424/12424 [==============================] - 3s 278us/sample - loss: 0.1035 - mae: 0.2357 - val_loss: 0.0998 - val_mae: 0.2324\n",
      "Epoch 18/50\n",
      "12424/12424 [==============================] - 4s 285us/sample - loss: 0.1030 - mae: 0.2357 - val_loss: 0.0935 - val_mae: 0.2288\n",
      "Epoch 19/50\n",
      "12424/12424 [==============================] - 4s 289us/sample - loss: 0.1022 - mae: 0.2331 - val_loss: 0.0975 - val_mae: 0.2332\n",
      "Epoch 20/50\n",
      "12424/12424 [==============================] - 4s 287us/sample - loss: 0.1019 - mae: 0.2340 - val_loss: 0.1113 - val_mae: 0.2420\n",
      "Epoch 21/50\n",
      "12424/12424 [==============================] - 4s 284us/sample - loss: 0.1023 - mae: 0.2351 - val_loss: 0.1057 - val_mae: 0.2390\n",
      "Epoch 22/50\n",
      "12424/12424 [==============================] - 4s 284us/sample - loss: 0.1021 - mae: 0.2326 - val_loss: 0.1049 - val_mae: 0.2402\n",
      "Epoch 23/50\n",
      "12424/12424 [==============================] - 3s 279us/sample - loss: 0.1011 - mae: 0.2327 - val_loss: 0.0946 - val_mae: 0.2305\n",
      "Epoch 24/50\n",
      "12424/12424 [==============================] - 4s 326us/sample - loss: 0.1011 - mae: 0.2326 - val_loss: 0.0928 - val_mae: 0.2273\n",
      "Epoch 25/50\n",
      "12424/12424 [==============================] - 4s 291us/sample - loss: 0.1002 - mae: 0.2322 - val_loss: 0.0920 - val_mae: 0.2293\n",
      "Epoch 26/50\n",
      "12424/12424 [==============================] - 4s 283us/sample - loss: 0.1011 - mae: 0.2328 - val_loss: 0.0981 - val_mae: 0.2318\n",
      "Epoch 27/50\n",
      "12424/12424 [==============================] - 4s 284us/sample - loss: 0.0993 - mae: 0.2302 - val_loss: 0.0919 - val_mae: 0.2257\n",
      "Epoch 28/50\n",
      "12424/12424 [==============================] - 3s 263us/sample - loss: 0.1009 - mae: 0.2314 - val_loss: 0.0919 - val_mae: 0.2322\n",
      "Epoch 29/50\n",
      "12424/12424 [==============================] - 4s 338us/sample - loss: 0.1001 - mae: 0.2310 - val_loss: 0.0955 - val_mae: 0.2315\n",
      "Epoch 30/50\n",
      "12424/12424 [==============================] - 3s 263us/sample - loss: 0.1000 - mae: 0.2316 - val_loss: 0.0979 - val_mae: 0.2317\n",
      "Epoch 31/50\n",
      "12424/12424 [==============================] - 4s 307us/sample - loss: 0.0994 - mae: 0.2303 - val_loss: 0.0937 - val_mae: 0.2266\n",
      "Epoch 32/50\n",
      "12424/12424 [==============================] - 4s 318us/sample - loss: 0.0992 - mae: 0.2308 - val_loss: 0.0994 - val_mae: 0.2345\n",
      "Epoch 33/50\n",
      "12424/12424 [==============================] - 3s 269us/sample - loss: 0.0988 - mae: 0.2295 - val_loss: 0.0939 - val_mae: 0.2274\n",
      "Epoch 34/50\n",
      "12424/12424 [==============================] - 3s 272us/sample - loss: 0.0983 - mae: 0.2290 - val_loss: 0.1013 - val_mae: 0.2404\n",
      "Epoch 35/50\n",
      "12424/12424 [==============================] - 3s 269us/sample - loss: 0.0982 - mae: 0.2292 - val_loss: 0.0934 - val_mae: 0.2259\n",
      "Epoch 36/50\n",
      "12424/12424 [==============================] - 3s 268us/sample - loss: 0.0981 - mae: 0.2290 - val_loss: 0.0938 - val_mae: 0.2268\n",
      "Epoch 37/50\n",
      "12424/12424 [==============================] - 3s 274us/sample - loss: 0.0998 - mae: 0.2310 - val_loss: 0.0946 - val_mae: 0.2312\n",
      "Epoch 38/50\n",
      "12424/12424 [==============================] - 3s 277us/sample - loss: 0.0987 - mae: 0.2299 - val_loss: 0.0893 - val_mae: 0.2245\n",
      "Epoch 39/50\n",
      "12424/12424 [==============================] - 3s 275us/sample - loss: 0.0969 - mae: 0.2272 - val_loss: 0.0960 - val_mae: 0.2284\n",
      "Epoch 40/50\n",
      "12424/12424 [==============================] - 4s 283us/sample - loss: 0.0978 - mae: 0.2281 - val_loss: 0.0901 - val_mae: 0.2251\n",
      "Epoch 41/50\n",
      "12424/12424 [==============================] - 4s 316us/sample - loss: 0.1030 - mae: 0.2343 - val_loss: 0.1017 - val_mae: 0.2375\n",
      "Epoch 42/50\n",
      "12424/12424 [==============================] - 4s 295us/sample - loss: 0.0984 - mae: 0.2290 - val_loss: 0.0933 - val_mae: 0.2230\n",
      "Epoch 43/50\n",
      "12424/12424 [==============================] - 4s 292us/sample - loss: 0.0955 - mae: 0.2258 - val_loss: 0.0963 - val_mae: 0.2303\n",
      "Epoch 44/50\n",
      "12424/12424 [==============================] - 4s 294us/sample - loss: 0.0951 - mae: 0.2251 - val_loss: 0.0921 - val_mae: 0.2226\n",
      "Epoch 45/50\n",
      "12424/12424 [==============================] - 4s 306us/sample - loss: 0.0955 - mae: 0.2255 - val_loss: 0.0970 - val_mae: 0.2270\n",
      "Epoch 46/50\n",
      "12424/12424 [==============================] - 4s 307us/sample - loss: 0.0984 - mae: 0.2288 - val_loss: 0.1008 - val_mae: 0.2293\n",
      "Epoch 47/50\n",
      "12424/12424 [==============================] - 3s 280us/sample - loss: 0.0949 - mae: 0.2252 - val_loss: 0.1011 - val_mae: 0.2292\n",
      "Epoch 48/50\n",
      "12424/12424 [==============================] - 4s 283us/sample - loss: 0.0953 - mae: 0.2255 - val_loss: 0.0953 - val_mae: 0.2274\n",
      "Epoch 49/50\n",
      "12424/12424 [==============================] - 3s 273us/sample - loss: 0.0987 - mae: 0.2301 - val_loss: 0.0872 - val_mae: 0.2234\n",
      "Epoch 50/50\n",
      "12424/12424 [==============================] - 3s 272us/sample - loss: 0.0971 - mae: 0.2278 - val_loss: 0.1026 - val_mae: 0.2331\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x = X_train, y = y_train, validation_data = (X_test, y_test), epochs=50, batch_size = 64)\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[8.513754 ],\n",
       "        [8.359654 ],\n",
       "        [8.362559 ],\n",
       "        [8.096525 ],\n",
       "        [7.8679805],\n",
       "        [8.8309965],\n",
       "        [8.591897 ],\n",
       "        [8.43015  ],\n",
       "        [8.434506 ],\n",
       "        [8.665655 ]], dtype=float32),\n",
       " array([[8.54500289],\n",
       "        [8.37047041],\n",
       "        [8.69484149],\n",
       "        [7.71760729],\n",
       "        [7.7403941 ],\n",
       "        [8.80751024],\n",
       "        [8.25992587],\n",
       "        [8.85311972],\n",
       "        [8.44308082],\n",
       "        [8.96784072]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10], y_test.to_numpy()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10259744167189298, 0.23314696337492352)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mean_squared_error(predictions, y_test), mean_absolute_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15fdf31cf08>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 150\n",
    "plt.plot(range(0, len(history.history[\"loss\"])), history.history[\"loss\"][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the value of number_of_rooms : 1\n",
      "Enter the value of floor_on : 2\n",
      "Enter the value of total_floors : 3\n",
      "Enter the value of bedroom : 2\n",
      "Enter the value of pincode : 12209\n",
      "Enter the value of balkon : 1\n",
      "Enter the value of terrasse : 1\n",
      "Enter the value of garten : 0\n",
      "Enter the value of Gaste-WC : 1\n",
      "Enter the value of Aufzug : 1\n",
      "Enter the value of wohung : 1\n",
      "Enter the value of construction_year : 1990\n",
      "Enter the value of living_area_m2 : 54.87\n"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for i in data.columns[:-1]:\n",
    "    value = float(input('Enter the value of {} : '.format(i)))\n",
    "    array.append(value)\n",
    "#sq = float(input('cs'))\n",
    "#array.append(np.log1p(sq))\n",
    "str_to_float = [[float(i) for i in array]]\n",
    "two_dim = str_to_float\n",
    "#sqr_living_m2 = two_dim[-1][0]\n",
    "#(two_dim)\n",
    "#model.predict(two_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0, 3.0, 2.0, 12209.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1990.0, 54.87]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.87"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_dim[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.9857206]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to = pd.DataFrame(two_dim)\n",
    "score = model.predict(to)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of house is [[59264.273]]\n"
     ]
    }
   ],
   "source": [
    "original_score = np.expm1(score) * two_dim[-1][-1]\n",
    "print('The price of house is {}'.format(original_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expm1(6.595112) * 36.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the value of number_of_rooms : 1\n",
      "Enter the value of floor_on : 2\n",
      "Enter the value of total_floors : 3\n",
      "Enter the value of bedroom : 2\n",
      "Enter the value of pincode : 12209\n",
      "Enter the value of balkon : 3\n",
      "Enter the value of terrasse : 2\n",
      "Enter the value of garten : 1\n",
      "Enter the value of Gaste-WC : 1\n",
      "Enter the value of Aufzug : 1\n",
      "Enter the value of wohung : 1\n",
      "Enter the value of construction_year : 2000\n",
      "living_sq_m267\n"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for i in data.columns[:-2]:\n",
    "    value = float(input('Enter the value of {} : '.format(i)))\n",
    "    array.append(value)\n",
    "sq = float(input('living_sq_m2'))\n",
    "array.append(np.log1p(sq))\n",
    "str_to_float = [[float(i) for i in array]]\n",
    "two_dim1 = str_to_float\n",
    "#sqr_living_m2 = two_dim[-1][0]\n",
    "#(two_dim)\n",
    "#model.predict(two_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.636968]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.predict(pd.DataFrame(two_dim1))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The price of house is [[377559.25]]\n"
     ]
    }
   ],
   "source": [
    "original_score = np.expm1(score) * np.expm1(two_dim1[-1][-1])\n",
    "print('The price of house is {}'.format(original_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "for i in data.columns[:-2]:\n",
    "    value = float(input('Enter the value of {} : '.format(i)))\n",
    "    array.append(value)\n",
    "sq = float(input('living_sq_m2'))\n",
    "array.append(np.log1p(sq))\n",
    "str_to_float = [[float(i) for i in array]]\n",
    "two_dim2 = str_to_float\n",
    "#sqr_living_m2 = two_dim[-1][0]\n",
    "#(two_dim)\n",
    "#model.predict(two_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = model.predict(pd.DataFrame(two_dim2))\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_score = np.expm1(score1) * np.expm1(two_dim2[-1][-1])\n",
    "print('The price of house is {}'.format(original_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the value of number_of_rooms : 1\n",
      "Enter the value of floor_on : 2\n",
      "Enter the value of total_floors : 3\n",
      "Enter the value of bedroom : 2\n",
      "Enter the value of pincode : 12345\n",
      "Enter the value of balkon : 3\n",
      "Enter the value of terrasse : 2\n",
      "Enter the value of garten : 1\n",
      "Enter the value of Gaste-WC : 1\n",
      "Enter the value of Aufzug : 1\n",
      "Enter the value of wohung : 1\n",
      "Enter the value of construction_year : 2000\n",
      "living_sq_m267\n",
      "[[1.0, 2.0, 3.0, 2.0, 12345.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2000.0, 4.219507705176107]]\n",
      "The price of house is [[377559.25]]\n"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for i in data.columns[:-2]:\n",
    "    value = float(input('Enter the value of {} : '.format(i)))\n",
    "    array.append(value)\n",
    "sq = float(input('living_sq_m2'))\n",
    "array.append(np.log1p(sq))\n",
    "str_to_float = [[float(i) for i in array]]\n",
    "two_dim3 = str_to_float\n",
    "print(two_dim3)\n",
    "score3 = model.predict(pd.DataFrame(two_dim3))\n",
    "original_score = np.expm1(score3) * np.expm1(two_dim3[-1][-1])\n",
    "print('The price of house is {}'.format(original_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[377556.3]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(score3) * np.expm1(4.21950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.219507705176107"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log1p(67\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:10], y_test.to_numpy()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mean_squared_error(predictions, y_test), mean_absolute_error(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "plt.plot(range(1, len(history.history[\"loss\"])), history.history[\"loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(history.history[\"val_loss\"])), history.history[\"val_loss\"][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_ftt = X_test.head(10)\n",
    "sqr_ft = sq_ftt['living_area_m2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictions[:10]\n",
    "p = p.tolist()\n",
    "y_test = y_test[:10]\n",
    "\n",
    "y_t = y_test.to_numpy().tolist()\n",
    "y_t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j, k in zip(y_t, sqr_ft, p):\n",
    "    print('true',np.exp(i) * np.exp(j))\n",
    "    print('pred',np.exp(k) * np.exp(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "for i in data.columns[:-1]:\n",
    "    value = float(input('Enter the value of {} : '.format(i)))\n",
    "    array.append(value)\n",
    "sq = float(input('cs'))\n",
    "array.append(np.log1p(sq))\n",
    "str_to_float = [[float(i) for i in array]]\n",
    "two_dim = str_to_float\n",
    "sqr_living_m2 = two_dim[-1][-1]\n",
    "score = model.predict([[2.0, 2.0, 2.0, 2.0, 12209.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1980.0, 4.04]])\n",
    "score\n",
    "original_score = np.expm1(score) * np.expm1(sqr_living_m2)\n",
    "print('The price of house is {}'.format(original_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.predict([[2.0, 2.0, 2.0, 2.0, 12209.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1980.0, 4.04]])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
